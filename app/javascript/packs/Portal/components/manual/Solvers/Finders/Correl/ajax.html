<html><head>
<STYLE TYPE="text/css">
<TITLE>Solver AJAX</TITLE>
<!--
.indented
   {
   padding-left: 25pt;
   padding-right: 25pt;
   }
-->
</STYLE>
</head>
<body text="#000066">
<A NAME="AJAX" ID="AJAX"><H1 align=center>Solver AJAX</H1></A>

<P>AJAX solves the implicit algebraic equations<br><br>

&nbsp;&nbsp;&nbsp;&nbsp;<i>g<SUB>1</SUB>(x<SUB>1</SUB>,...,x<SUB>n</SUB>) = 0</i><BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<i>g<SUB>m</SUB>(x<SUB>1</SUB>,...,x<SUB>n</SUB>) = 0</i><BR><br>

by successive approximation of the unknowns. 
(See <A href="../../../Man/chap2/FCMANC2.html#IP1:IMALEQ">Implicit Algebraic Equations</A>,
<A href="../../../Man/chap2/FCMANC2.html#IP2:EIMALEQ">Implicit Algebra Simulation</A>,
<A href="../../../Man/chap2/FCMANC2.html#IP3:IMALCO">Implicit Algebra Correlation</A>)</p>

<p>The model procedure 
is executed iteratively until the constraints are matched to zero 
within a specified tolerance.  During each iteration of this process, 
the approximation of the unknown vector is computed according to the
"damped" Newton formula employing the inverse of the Jacobian matrix
(whose columns are the gradient vectors of the constraints) evaluated
during the previous Newton iteration, to forecast a step change in the
unknowns vector. This step change is then reduced by a dampling factor,
and subiterations are taken in the Newton direction using the damped step,
finding the nearest approach to the zeros of the constraints in that
direction. Thus if the function is locally non-quadratic, causing the
undamped Newton method to oscillate, damping will compensate for it.</p>


<A NAME="FIND" ID="FIND"><H2>AJAX FIND Statement</H2></A>
<p>The FIND statement for AJAX takes the following form:</p>
<blockquote>
<B>FIND</B> <i>unknowns</i><B> IN</B> <i>model</i>
   <B>BY AJAX</B> {<B>(</b><i>controller</i><B>)</B>}<BR>
&nbsp;&nbsp;{<B>WITH</B>|<B>AND</B>} <B>LOWER</B> <i>floor</i><B></B>} 
    {<B>WITH</B>|<B>AND</B>} <B>UPPER</B> <i>ceiling</i><B></B>}<BR>
&nbsp;&nbsp;{<B>REPORTING</B> <i>auxiliaries</i>} {<B>WITH FLAG</B> <i>signal</i><B></B>}<BR>
&nbsp;&nbsp;<B>TO MATCH</B> <i>constraints</i>
</blockquote>

<p>AJAX will solve systems of equations which fall within any of the 
three classes of simultaneous equations<br><br>
&nbsp;&nbsp;&nbsp;&nbsp;(1) Determined systems - equal number of equations and unknowns,<br>
&nbsp;&nbsp;&nbsp;&nbsp;(2) Overdetermined systems - more equations than unknowns, and<br>
&nbsp;&nbsp;&nbsp;&nbsp;(3) Underdetermined systems - fewer equations than unknowns.<br><br>

For determined systems, the Newton formula employs the true inverse of
the square Jacobian matrix. In the actual computation of AJAX, the inverse
is not determined, per se, rather its equivalent combined form is computed 
by a process known as sequential orthogonalization. The net effect 
is the same as if the inverse were determined, but is more efficient.</p>

<p>If the equations have more than one solution, as is usually true of 
nonlinear equations, the particular solution obtained will be the 
one nearest to the initial approximation of the unknowns 
(the values of these variables upon initial execution of the model 
procedure).</p>

<p>For overdetermined systems, no true solution exists. However, AJAX assumes
that the greater number of equations represent redundant approximations to
the equations and solves the system by the method of least squares. Again,
the particular solution obtained will be the one nearest to the initial
approximation. In this case, the matrix employed is the pseudo-inverse 
of the Jacobian matrix. This matrix which has all of the relevant properties
of a true inverse when used in place of a true inverse, even though the
Jacobian matrix is singular or nonsquare, and its true inverse does not exist.</p> 

<p>For underdetermined systems, the number of equations is fewer than the number
of independent variables. The equivalent situation can also occur in
determined (square) systems if the equations are unstable (ill-conditioned). 
Loosely stated, a system of equations is numerically unstable if small changes
in the coefficients of the equations produce large changes in the solution. 
Apparent changes in coefficient values could arise due to the precision of
matrix inversion. In either case, underdetermined or ill-conditioned, an
infinite number of solutions exist. However, by minimizing the Euclidean
norm (sum of squares of the risidual deviations from zero) of the unknowns,
AJAX will find one of a finite number of smallest least squares solutions to
the nonlinear equations.  The particular solution obtained will be the one
nearest to the initial approximation of the unknowns. In this case this case,
the matrix used in the Newton formula is the pseudo-inverse of the Jacobian
matrix. In essence the underdetermined case is a minimization problem in
which the Eucledian norm is the objective function to be minimized.</p>

<p>In the case where the equations to be solved are linear, there is only one
solution for each of the determined, overdetermined, or underdetermined/ill-
onditioned cases.  The linear solution is achieved in a single execution of
the model by AJAX.</p>

<A NAME="CONTROLS" ID="CONTROLS"><h2 align=center>AJAX Controls</h2></A>

<TABLE border=2>
<caption>The control variables for AJAX are as follows.</caption>

<TR valign=bottom bgcolor=#00FFFF>
<TH>Variable</TH>
<TH>Preset<br>Value</TH>
<TH>Value</TH>
<TH align=left>Option</TH>
</TR>

<TR>
<TD rowspan=3><B>DETAIL</B></TD>
<TD rowspan=3>0</TD>
<TD>0</TD>
<TD>No detailed report</TD>
</TR>

<TR>
<TD>1</TD>
<TD>Detailed report for every iteration</TD>
</TR>

<TR>
<TD>n</TD>
<TD>Detailed report for iterations initial,n,2n,...,last</TD>
</TR>

<TR>
<TD rowspan=2><B>SUMMARY</B></TD>
<TD rowspan=2>1</TD>
<TD>0</TD>
<TD>No summary report</TD>
</TR>

<TR>
<TD>1</TD>
<TD>Generate solution summary</TD>
</TR>

<TR>
<TD rowspan=2><B>CONVERGE</B></TD>
<TD rowspan=2>1</TD>
<TD>1</TD>
<TD>Satisfy constraints convergence or unknowns convergence</TD>
</TR>

<TR>
<TD>2</TD>
<TD>Satisfy constraints convergence and unknowns convergence</TD>
</TR>

<TR>
<TD><B>REMAX</B></TD>
<TD>20</TD>
<TD></TD>
<TD>Maximum number of allowed iterations</TD>
</TR> 

<TR>
<TD><B>ZERO</B></TD>
<TD>10<SUP>-6</SUP></TD>
<TD></TD>
<TD>Zero tolerance for constraints convergence</TD>
</TR>

<TR>
<TD><B>DELTA</B></TD>
<TD>10<SUP>-7</SUP></TD>
<TD></TD>
<TD>Tolerance on change in unknowns for unknowns convergence</TD>
</TR>

<TR>
<TD rowspan=2><B>BREAKIN</B></TD>
<TD rowspan=2>0</TD>
<TD>0</TD>
<TD>No interactive breakpoints</TD>
</TR>

<TR>
<TD>n</TD>
<TD>Breakpoint after every nth iteration</TD>
</TR>

<TR>
<TD><B>VLIMIT</B></TD>
<TD>10<SUP>50</SUP></TD>
<TD></TD>
<TD>Limit on the maximum change of the independent variables during a single iteration</TD>
</TR>

<TR>
<TD><B>DAMP</B></TD>
<TD>0.2</TD>
<TD></TD>
<TD>Criteria for imposing damping</TD>
</TR>

<TR>
<TD rowspan=3><B>DETOUT</B></TD>
<TD rowspan=3>+1</TD>
<TD>0</TD>
<TD>Detailed report to PRINTER</TD>
</TR>

<TR>
<TD>+1</TD>
<TD>Detailed report to SCROLL</TD>
</TR>

<TR>
<TD>-1</TD>
<TD>Detailed report to Console</TD>
</TR>

<TR>
<TD rowspan=3><B>SUMOUT</B></TD>
<TD rowspan=3>+1</TD>
<TD>0</TD>
<TD>Summary report to PRINTER</TD>
</TR>

<TR>
<TD>+1</TD>
<TD>Summary report to SCROLL</TD>
</TR>

<TR>
<TD>-1</TD>
<TD>Summary report to Console</TD>
</TR>

<TR>
<TD><B>TAU</B></TD>
<TD>0.001</TD>
<TD></TD>
<TD>Maximum relative error in the constraints being matched, i.e. max (error-G)/G. 
TAU must be positive. TAU permits the specification of the approximate error in the 
values computed in the calculus model, for example errors due to measurement uncertainty 
in a data fitting problem. This value is used to hold computational error to a point where 
it is negligible in comparison to the a priori Error. The value is also used to determine 
the rank of the problem, i.e. the larger the value of TAU the more likely that the problem 
is rank deficient (ill-conditioned or singular). Obviously, an unreasonably small value for 
TAU may obscure the true nature of the problem and at the same time provoke unnecessarily 
extended computation.</TD>
</TR>

<TR>
<TD><B>PREDAMP</B></TD>
<TD>1</TD>
<TD></TD>
<TD>Arbitrary damping factor to be applied to the first iteration. 
(0 &le; <B>PREDAMP</B> &le; 1) PREDAMP is used only when damping is applied (control 
variable DAMP nonzero). The damping scheme involves a comparison of successive estimates of 
the norm of the constraints and hence cannot be applied to the initial estimate. Thus, 
there is some possibility of an inordinately large Newton step on the first iteration. 
When this is anticipated, perhaps from a previous attempt at a solution, PREDAMP may be 
used to limit the first step.</TD>
</TR>

</TABLE>

</body>
</html>
