<html><head>
<STYLE TYPE="text/css">
<!--
.indented
   {
   padding-left: 25pt;
   padding-right: 25pt;
   }
.style1 {
	margin-left: 40px;
}
.style2 {
	border-width: 1px;
	text-align: center;
}
.style4 {
	border-width: 1px;
}
.style5 {
	border: 1px solid #000000;
}
.style6 {
	border-style: solid;
	border-width: 1px;
}
.style7 {
	border-width: 0;
}
.style8 {
	border: 1px solid #000000;
	text-align: center;
}
-->
</STYLE>
</head>
<body>
<A NAME="ORDIFEQ" ID="ORDIFEQ"><H1 ALIGN=CENTER>5. Ordinary Differential Equations</H1></A>

<p>An equation containing derivatives of a dependent variable with respect 
to an independent variable, such as</p>

&nbsp;&nbsp;&nbsp;&nbsp;<I>dy/dx = xe<sup>y</sup></I><br><br>

is an ordinary differential equation (ODE).  The term "ordinary" refers 
to the fact that the derivative dy/dx (often written y&prime;) 
is an ordinary one, not a partial derivative.  When no higher order 
derivatives appear, such as d<sup>2</sup>y/dx<sup>2</sup>, the equation is 
a <I>first order</I> ODE.

The central problem of integral calculus is the solution of such equations, 
i.e., determining the function <i>y=f(x)</i> which satisfies the ODE.  When 
a numerical solution is calculated, the curve is determined by a table 
of values of y as a function of x.  In many practical applications, 
of course, there is more than one dependent variable, resulting in 
systems of equations of the form<BR><BR>

&nbsp;&nbsp;&nbsp;&nbsp;<I>y<sub>1</sub>&prime; = f<sub>1</sub>(x, y<sub>1</sub>,..., 
y<sub>n</sub>)</i><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<I>y<sub>n</sub>&prime; = f<sub>n</sub>(x, y<sub>1</sub>,..., 
y<sub>n</sub>)</i><br><br>

When they may be written in this form, where there are only first 
derivatives and where the functions <I>f</I> do not contain derivatives, 
the equations are called a normal system.  Many techniques for the 
solution of ODEs require that they be reduced to normal systems.<p>Unfortunately, however, the real world abounds with <I>implicit</I> 
equations such as<br>
<div style="margin-left: 50px">
<img src="../images/ImpdesEq1.png" height="54" width="389">
</div>

<div style="margin-left: 50px">
<img src="../images/ImpdesEq2.png" height="54" width="397">
</div>

which cannot be reduced to a normal form.  Furthermore, there are 
often higher order derivatives <I>(y&prime;&prime;,y&prime;&prime;&prime;,etc.)</I> 
involved.  (When this is the only complication, the system of equations 
can be reduced to a set of first order equations by introducing new 
variables and associated equations.)<p>In FC any of the equations described above may be solved <I>exactly 
as they are expressed</I>.  These is no need for reductions, transformations, 
the introduction of new variables, or any other artifice.  In general, 
there may be any number of equations, they may be linear or nonlinear, 
they may be explicit or implicit, and they may be of any order.</p>

<p>In order to permit their solution, ODEs must be accompanied by additional 
information in the form of initial or boundary conditions. When these 
conditions are provided for a single value of the independent variable, 
e.g.,<I> y(x<SUB>0</SUB>)=y<SUB>0</SUB></I>, the problem is called an initial 
value problem.  On the other hand, if <I>y </I>or its derivatives 
(for higher order ODEs) are specified for two or more values of the 
independent variable, the problem is called a boundary value problem. 
It is well known that a unique solution of an <I>n</I>th order initial 
value problem is determined by specifying <I>n</I> appropriate conditions 
at one point.  This is true in general because the solution of such 
a problem has <I>n</I> constants of integration, and to provide numerical 
answers, <I>n</I> initial conditions are needed to determine these 
constants.  If this is a system of <I>m</I> such <I>n</I>th order 
equations, then a total of (<I>m</I> by <I>n</I>) initial conditions 
must be supplied.</p>

<p>For the <I>n</I>th order boundary problem, there are also <I>n</I> 
constants of integration to be determined.  In this case, however, 
for a given set of <I>n</I> boundary conditions, it is possible for 
the <I>n</I>th order equation to have many solutions or even no solution 
at all!  Thus it is vital to select the boundary conditions carefully, 
so that the problem to be solved is well-defined and has a unique 
solution.</p>

<p>The Fortran Calculus ODE solvers are step-by-step numerical integration 
techniques. A brief description of these solvers is given in Table 5-1, below.</p>
<HR>
<table style="width: 100%" class="style7">
	<tr>
		<td class="style2" style="height: 26px"></td>
		<td class="style8" colspan="2" style="height: 26px">TABLE 5-1 Differential Equations Solvers&nbsp;</td>
		<td class="style2" style="height: 26px; width: 150"></td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">ATHENA&nbsp;</td>
		<td class="style5"><em>Derivative propagating, variable-order Runge-Kutta method with 
		output variable limiting.&nbsp;</em>ATHENA is a single step (nonmemory) 
		integration method which applies the Runge-Kutta method with orders 
		2,3,4,5. As a nonmemory Solver, it does not require reinitilization 
		whenever discontinuities in the differential equation are present. 
		Limits may be imposed upon the dependent variables of integration, and 
		partial derivatives may be propagated through the integration process, 
		allowing nesting of integration within optimization processes</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">GEMINI&nbsp;</td>
		<td class="style5"><em>Hybrid (propagating/nonpropagating) rational-function approximation 
		method.</em> GEMINI is a hybrid solver which automatically operates as MERLIN 
		when partial derivative propagaton is required, and operates as NEPTUNE 
		otherwise.&nbsp;</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">ISIS&nbsp;</td>
		<td class="style5"><em>Derivative-propagating, fourth-order Runge-Kutta-Gill method</em>. ISIS 
		is a memory solver designed as a recursive function allowing the 
		solution of nested differential equations. Partial derivatives may be 
		propagated through the integration process, allowing nesting of 
		integration within optimixation processes.&nbsp;</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="height: 25px; width: 127px" class="style4">&nbsp;</td>
		<td style="height: 25px; width: 120px" class="style5">JANUS</td>
		<td style="height: 25px" class="style5">N<em>onpropagating, fourth-order Adams-Moulton 
		method. </em>Janus is a memory method with an automatic procedure for varying 
		the integration step in order to improve execution efficiency by taking 
		the largest possible step for a given error criterion. It does not 
		propagate derivatives through integration, thus it may not be nested 
		within an optimizatio process.</td>
		<td style="height: 25px; width: 150;" class="style4">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">JANISIS&nbsp;</td>
		<td class="style5"><em>Hybrid (propagating/nonpropagating) fourth-order Runge-Kutta 
		Adams-Moulton method. J</em>ANISIS is a hybrid solver, which automatically 
		operates as ISIS when partial derivative propagation is required and 
		operates as JANUS otherwise.&nbsp;</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">MERCURY&nbsp;</td>
		<td class="style5"><em>Nonpropagating, optimal step size and stiff equation method equation 
		method of Gear.</em> MERCURY offers two predictor-corrector methods, an Adams 
		method and a special formulation by Gear for the solution of stiff 
		differential equations. MERCURY chooses both the order and the step size 
		in order to minimize problem solution time while holding truncatin error 
		with prescribed limits. MERCURY does not propagate derivates through 
		integration, thus it may not be nested within an optimization process. 
		However its does activate the evaluation of partial derivates within its 
		model, and uses the values of partial derivataives in the integration 
		process.</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">MERLIN</td>
		<td class="style5"><em>Derivative propagating, rational-function approximation method.</em> 
		MERLIN employs the memory technique of Gragg, Bullrsch and Stoer. It 
		optimizes both the step size and the order of approximaton so as to 
		minimize the computation necessary to satisfy a specified error bound. 
		It propagates partial derivatives through integration, allowing nesting 
		of integration within optimization processes.&nbsp;</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px; height: 26px" class="style4">&nbsp;</td>
		<td style="width: 120px; height: 26px" class="style5">MINERVA&nbsp;</td>
		<td style="height: 26px" class="style5"><em>Nonpropagating, variable-order Runge-Kutta 
		method with state variable limiting. </em>MINERVA is identical to ATHENA 
		except that it does not propgate derivatives through integration. THus 
		it may not be nested within optimization processes.</td>
		<td style="height: 26px; width: 150;" class="style4">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">NEPTUNE&nbsp;</td>
		<td class="style5"><em>Nonpropagating, rational function approximation method.
		</em>NEPTUNE is 
		identical to MERLIN except that it does not propagate derivatives 
		through integration. Thus it may not be nested within optimization 
		processes.&nbsp;</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 127px" class="style4">&nbsp;</td>
		<td style="width: 120px" class="style5">PEGASUS&nbsp;</td>
		<td class="style5"><em>Nonpropagating, fifth-order, Sarafyan-Runge-Kutta method with state 
		variable limiting.&nbsp;</em> PEGASUS employs a fifth order nonmemory RUnge-Kutta 
		technique known as Sarafyan imbedding which is used to optimize step 
		size for a given accuracy requirement requirement. Limits may be imposed 
		upon the state variables of integration. However, partial derivates are 
		not propagated through integration, thus PEGASUS may not be nested 
		within an optimization process.</td>
		<td class="style4" style="width: 150">&nbsp;</td>
	</tr>
</table>
<HR>
<p>Each time the calculus process is performed, by an INTEGRATE statement, 
the equations are integrated over a prescribed interval in a direction 
defined by the sign of the step.  Any solver may be used to integrate 
a single ODE or any number of simultaneous ODEs; and, as shown in 
Section 5.4, the equations may be of any order.</p>

<p>The basic techniques of the ODE solvers address the solution of explicit, 
initial value problems.  Implicit ODEs and boundary value problems 
are solved as combined processes, using the ODE solvers in conjunction 
with the general equation solver AJAX.  These techniques are described 
in Sections 5.5. and 5.6.</p>

<h2>Non-Propagating Solvers</h2>

<p>Integration solvers which do not propagate partial derivatives may 
only be employed in contexts where derivative evaluation is not active.  In 
general, these solvers are far more efficient than solvers which do 
propagate derivatives.  Consequently, they are preferred whenever 
derivative propagation is not required.</p>

<h3>Solver JANUS</h3>

<p>JANUS is a fourth order Adams-Moulton predictor-corrector method, 
employing a fourth order Runge-Kutta starting procedure.  The equations 
are integrated by the Runge-Kutta procedure until enough information 
has been accumulated to begin the predictor-corrector method, i.e., 
for three steps.  On the fourth step, the technique switches automatically 
to the Adams-Moulton method.</p>

<p>During the Runge-Kutta process, the differential equations are evaluated 
four times per step by executing the model four times. Once the Adams-Moulton 
procedure begins, the model is executed only two times per step, although 
the accuracy of the results is the same as for the Runge-Kutta steps.</p>

<p>JANUS cannot be "nested" within a calculus process which activates 
derivative evaluation; however, its model may include any calculus 
process except another integration involving JANUS.  For example, 
the differential equations may be implicit equations (see Section 
5.5.) or integro-differential equations using the definite integral 
functions (INTEGRAL, ROMBINT, etc.).</p>

<p>A major advantage of JANUS is that it employs an automatic procedure 
for varying the integration step in order to hold numerical error 
within prescribed limits.  When the controls associated with this 
procedure are properly set, the step size will be either increased 
or decreased in a manner which permits the largest possible step within 
defined error criteria.</p>

<B><I>Initiating JANUS</I></b> - The INITIATE statement for JANUS takes 
the following form:

<blockquote>
<B>INITIATE JANUS</B> {<B>(</B><I>controller</I><B>)</B>}<B>;</B> 
{<B>WITH</B>}<B>FLAG</B> <I>signal</I><B>;</B>} <br>
<B>FOR</B> <I>model</I><B>;</B> <B>EQUATIONS</B> <I>ode/vars</I><B>; OF</B>
<I>ind-var</I><b>;</b> <B>STEP</B> <I>delta</I><B>; TO</B> <I>limit</I>
</blockquote>

<p>The meaning and form of the symbols: <I>controller</I>, <I>model</I>, 
<I>ode/vars</I>, <I>ind-var</I>, <I>delta</I>, and <I>limit </I>are 
identical to those described for integration processes in Sections 
1.3 and 2.2.1</p>

<p>The equations are identified by the <I>ode/vars</I> list which specifies 
the names used in the <I>model</I> to represent the state  variables 
and their derivatives.  This list has the form<br><BR>

&nbsp;&nbsp;&nbsp;&nbsp;<I> der/var,der/var,...</I><BR><BR>

where <I>der</I> identifies ordinary derivatives and <I>var</I> identifies 
the corresponding dependent variables. For more detailed description, 
see Section 2.2.1.</p>

<p>The scalar variable <I>signal</I> is set by JANUS to denote its action 
with respect to step size control.  After each INTEGRATE statement, 
JANUS sets <I>signal</I> as follows:</p>

<DIV STYLE=indented><hr>
<TABLE><TR><th>Value</th><th>Meaning</th></tr>                                                              
<tr><TD>0</TD><td>The step size was either increased or unchanged.</td></tr>

<tr><TD>n</TD><td>The step size was decreased because of excessive 
 		error in the nth ODE.</td></tr></table><hr>
</div>
<p>The equations are numbered by their sequence  in the <I>ode/vars</I> list, not by their order of computation in 
the model.</p>

<p>The optional parenthesized phrase {<B>(</B><I>controller</I><B>)</B>} performs 
the usual function of identifying a controller so that control values 
may be changed for this use of JANUS.</p>

<p>The model must be a MODEL label, identifying the calculus model for 
this process.  This model must compute the ODEs and any auxiliary 
values which they require.  The MODEL may not have parameters, but 
may call other MODELs or FMODELs that do.</p>

<B><I>Executing JANUS</I></b>  -  Once the INITIATE statement has been executed, 
function generation is performed by JANUS whenever the statement

<p>&nbsp;&nbsp;&nbsp;&nbsp;<B>INTEGRATE</B> <I>model</I><b>; BY JANUS</b><br><br>

is executed.  This statement generates the integral function up to 
the limit value of <I>ind-var</I>.</p> 

<p>This statement generates no printed output.  If the values at the 
end of a step are required, they must be printed by ordinary FORTRAN 
output statements.</p>

<H4>Example</H4>

<p>If the integration was initiated by</p>

<b><PRE>
       X = 0   : Y = 1 :  T = 0  :  DT = 0.01
      INITIATE JANUS; FOR DIFF; EQUATIONS  XDOT/X, YDOT/Y;
         OF T;  STEP DT; TO TF
</PRE>     </b>    

<p>then integration up to T = 1, with printing at .1,.2,.3,... may be 
performed by</p>

<b><PRE>
       TF = 0
      DO WHILE (TF.LT.1)
         TF=TF+.1 
         INTEGRATE DIFF; BY JANUS
      END DO
</PRE></b>

<p>If the values of any of the dependent variables or the independent 
variable are altered after the INITIATE statement, this imposes a 
discontinuity in the equations.  In fact, this really defines a new 
initial value problem.  While this is perfectly valid, it is mandatory 
that an INITIATE statement be executed once more before continuing 
integration.  This is necessary because the Adams-Moulton procedure 
maintains a "memory" of previous steps.  On the other hand, the step 
size may be modified at will between INTEGRATE statements.  (If this 
is done, JANUS will automatically reimpose its Runge-Kutta starting 
procedure in order to refresh its memory.)</p>

<P><B><I>Controlling JANUS</I></B> - JANUS has four control variables, all 
associated with its automatic step size adjustment.  They are as follows:

<DIV STYLE="indented"><hr>
<TABLE class="style5">
<TR>
<TH ALIGN=LEFT>Variable</TH>
<TH ALIGN=LEFT>Description</TH>
<TH ALIGN=RIGHT>Preset Value</TH>
</TR>

<TR WIDTH=100%>
<TD VALIGN=TOP WIDTH=15%><B>ERRLO</B></TD>
<TD><b>Fractional error lower limit.</b><BR>
If the relative predictor-corrector errors (The relative error is the absolute error divided 
by the magnitude of the dependent variable.) for all equations are less than this value then 
the step size is doubled for use on the next step. The upper limit is STEPMAX.</TD>
<TD VALIGN=TOP>10<SUP>-7</SUP></TD>
</TR>

<TR WIDTH=100%>
<TD VALIGN=TOP><B>ERRHI</B></TD>
<TD><B>Fractional error upper limit</B><BR>
If any equation generates a relative error greater than this value, the step size is halved 
and the integration step is reexecuted at the lower value. This may occur repeatedly during 
one step if the resulting error is still too large. The lower limit is STEPMIN.</TD>
<TD VALIGN=TOP>10<SUP>-4</SUP></TD>		
</TR>                                                            

<TR WIDTH=100%>
<TD VALIGN=TOP><B>STEPMAX</B></TD>
<TD><B>Maximum step size.</B><BR>The preset value is effectively no limit.</TD>
<TD VALIGN=TOP>10<SUP>9</SUP></TD>	
</TR>

<TR WIDTH=100%>
<TD VALIGN=TOP><B>STEPMIN</B></TD>
<TD><B>Minimum step size</B><BR>The preset value allows the adjustment control 
to be effectively free to reduce the steps. If no real limit is imposed, it is desirable 
to test the step size periodically while integrating in order to see if it is decreasing 
unreasonably.  Often this is a good indication of a poorly posed problem.</TD>
<TD VALIGN=TOP>10<SUP>-9</SUP></TD>
</TR>

</TABLE><HR></DIV>		      								

  



<h2>Solver MERCURY</H3> 

MERCURY applies  Gear's method<$FA brief description is given in: 
Gear, C.W., "The Automatic Integration of Ordinary Differential Equations," 
<I>Communications of the ACM</I> 14,3 (Mar 1971), 176-179.  A more 
comprehensive discussion may  be found in:  Gear, C.W., <MI>Numerical 
Initial Value Problems in Ordinary Differential Equation<D>s, Prentice 
Hall, 1971. >  for integration of ordinary differential equations.  As 
with other FC integration solvers, MERCURY is suitable for both linear 
and nonlinear systems of arbitrary number and degree.  It has, however, 
two unique capabilities as described below.
<UL>
<LI><I>Stiff  ODE Systems</I>  -  An ODE system is termed stiff 
when it contains greatly differing time constants or oscillation frequencies. 
Conventional integration techniques are impractical for such systems 
because they require inordinately small step sizes to achieve acceptable 
accuracy and stability.  MERCURY offers two predictor-corrector algorithms, 
an Adams method and a special formulation designed by GEAR for the 
solution of stiff systems.</LI>

<LI><I>Optimal Step Size</I>  -  Regardless of which algorithm 
is selected, MERCURY chooses both the order and step size so as to 
minimize problem solution time while holding truncation error within 
prescribed limits.  For the Adams method, the order may be from 1 
to 13; for the stiff method it may range from 1 to 6.  The gain in 
efficiency depends upon the length of the integration span and the 
character of the equations.  However, improvements of one or more 
orders of magnitude are not unusual.</LI>
</UL>

<P><B><I>Derivative Evaluation</I></B> -  MERCURY automatically activates the 
evaluation of partial derivatives with respect to the dependent variables 
of integration.<$FThis means that MERCURY cannot be nested inside 
another calculus process.>   If these variables are changed by FC 
statements in the model, a warning diagnostic will be issued indicating 
that a change in an independent variable (of derivative evaluation) 
may invalidate existing partial derivatives.

<P><B><I>Initiating MERCURY</I></B>  -  The INITIATE statement for MERCURY takes 
the general form

<p><B>INITIATE MERCURY </B>(<I>controller);</I> 
<B>FOR</B> <I>model</I>;  <B>EQUATIONS</B><i>ode/vars</I>;<br>
<b>OF </B><i>ind-var</I><B>;  STEP </B><I>delta</I> <B>TO</B> <I>limit</I>
<P>The meaning and from of the symbols:<I> controller</I>,<I> model</I>, 
<I>ode/vars</I>, <I>ind-var</I>,<I> delta</I> and limit are identical 
to those described for integration processes in Sections 1.3 and 2.2.1.</P>

<P><B><I>Executing MERCURY</I></B>  -  The integral function is generated by 
MERCURY whenever the statement

<P><B> INTEGRATE</B> <I>model<B>;</B> <B>BY MERCURY</B>

is executed.  Partial derivative evaluation is activated and a sequence 
of integration steps is performed until<I> ind-var</I> reaches the 
value specified by <I>limit</I>.  During integration, the step size 
will be modified to minimize the amount of computation required.  However, 
the value of <I>delta</I> will not be changed.  Rather, this value 
is used merely as an initial estimate.  To obtain the best results, 
the value of <I>delta</I> should be considerably smaller than the 
expected average step size, perhaps by one or two orders of magnitude.

<P><B><I>Terminating MERCURY</I></B>  - When integration has reached the limit, 
partial derivative evaluation is deactivated and execution continues following 
the INTEGRATE statement. At this point, results may be analyzed or displayed, 
further integration may be performed, or the integration process may be ended by<P>
<B>TERMINATE  <I>model</I>

<P><B><I>Controlling MERCURY </I></B>-  MERCURY employs the following control 
variables:<br>

<table style="width: 100%" class="style5">
	<tr>
		<td>Variable</td>
		<td style="width: 869px">Description</td>
		<td>Present Value</td>
	</tr>
	<tr>
		<td>MAXERR</td>
		<td style="width: 869px">Relative error limit<span lang="en-us">.</span><br>The order of approximation and the step size are adjusted to assure that the largest relative truncation error does not exceed MAXERR, i.e., max(abs(error(y)/y))&nbsp; 
		&lt;&nbsp; MAXERR </td>
		<td>10<sup>-4</sup></td>
	</tr>
	<tr>
		<td style="height: 38px">STIFF </td>
		<td style="height: 38px; width: 869px;">
		<table style="width: 100%">
			<tr>
				<td style="height: 20px; width: 93px;"><span lang="en-us">Value</span>&nbsp;</td>
				<td style="height: 20px"><span lang="en-us">Opt</span><I><B><span lang="en-us">ion</span>&nbsp;</b></td>
			</tr>
			<tr>
				<td style="width: 93px"><span lang="en-us">=0</span>&nbsp;</td>
				<td>Selects the Adams method. This is more accurate and, in 
				general, more efficient for non-stiff ODEs.</td>
			</tr>
			<tr>
				<td style="width: 93px"><span lang="en-us">NOT = 0</span>&nbsp;</td>
				<td>(put symbol code) Selects the stiff method.&nbsp;&nbsp;This 
				method is suitable for both stiff and non-stiff systems. Where 
				there is doubt, it should be chosen.<br></td>
			</tr>This method is suitable for both stiff and non-stiff systems. Where there is doubt, it should be chosen.

		</table>
		<table>
		
        </tr>
        </table>
        </td>
		<td style="height: 38px">0</td>
	</tr>
<tr>
		<td>SAVE</td>
		<td style="width: 869px">SAVE Option to save generated points in a file. When set 
		non-zero, points of the generated function are saved, at increments of ind-var equal to +SAVE
		over the specified interval, for subsequent analysis
		or display.

		</td>
		<td>0&nbsp;</td>
	</tr>
        <tr>
		<td>STEPMAX</td>
		<td style="width: 869px">Maximum step-size.<br>
        The preset value effectively specifies no limit.
		Sometimes an upper limit is necessary to preserve
		stability of approximation.
		</td>
		<td>10<sup>9</sup></td>
	</tr>
    <tr>
		<td>STEPMIN</td>
		<td style="width: 869px">If error evaluation requires a step smaller than this value, integration terminates with a suitable diagnostic. Running time and round-off concerns @TABLE SUBITEM = may influence the use of a lower limit.</td>
		<td>10<sup>-9</sup> x Delta</td>
	</tr>
</table>

</b></i>
<P>Retrieval of the Integrated Functions  -  Because step-by-step 
integration is impractical for MERCURY, intermediate values of the 
generated functions are not readily accessible.  This restriction 
is minimized by activating the SAVE control variable.  When this is 
done, function values are saved on a scratch file (unit 98) during 
integration and may be retrieved after the INTEGRATE statement by 
reading the values from the file as follows:

<P class="style1"><B> READ(98)</b><I> ind-var</I>, <I>variable list</I>

</b>
<P>The data saved by <b>MERCURY</b> are:<P>&nbsp;<table style="width: 100%">
	<tr>
		<td style="width: 163px">&nbsp;</td>
		<td style="width: 216px">Index&nbsp;</td>
		<td style="width: 785px">Data&nbsp;</td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 163px">&nbsp;</td>
		<td style="width: 216px">1&nbsp;</td>
		<td style="width: 785px">Independent variable vector&nbsp;</td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td style="height: 25px; width: 163px;">&nbsp;</td>
		<td style="height: 25px; width: 216px;">2 ... n + 1</td>
		<td style="height: 25px; width: 785px;">Vectors of the n independent variable functions 
		from left to right in the <i>ode/var</i> list&nbsp;</td>
		<td style="height: 25px">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 163px">&nbsp;</td>
		<td style="width: 216px">n + 2 ... 2n + 1&nbsp;</td>
		<td style="width: 785px">Vectors of the relative truncation errors for the n dependent 
		variable vectors<sup>5</sup></td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td style="height: 26px; width: 163px;"></td>
		<td style="height: 26px; width: 216px;"></td>
		<td style="height: 26px; width: 785px;">Vectors of maximum value of above error vectors<sup>6</sup></td>
		<td style="height: 26px">&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 163px">&nbsp;</td>
		<td style="width: 216px">2n + 3&nbsp;</td>
		<td style="width: 785px">Vector of current step sizes&nbsp;</td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td style="width: 163px">&nbsp;</td>
		<td style="width: 216px">2n + 4&nbsp;</td>
		<td style="width: 785px">Vector of cumulative average step sizes<sup>7</sup>&nbsp;</td>
		<td>&nbsp;</td>
	</tr>
	<tr>
		<td style="height: 25px; width: 163px;">&nbsp;</td>
		<td style="height: 25px; width: 216px;">2n + 5</td>
		<td style="height: 25px; width: 785px;">Cumulative number of steps</td>
		<td style="height: 25px">&nbsp;</td>
	</tr>
</table>

		<h3>Example</h3><P>A particularly stiff set of ODE's

<PRE>     z<sub>i</sub> dot = -B<sub>i</sub>z<sub>i</sub + z<sub></sub><sup>2&nbsp;</sup>&nbsp;&nbsp;&nbsp; i = 1,2,3,4        [FIX. find this file with the dot]</PRE>
<P>has been proposed by F.T. Krogh, for testing stiff equation methods, 
where the B<MV>i<D> are the constants -10, .001, 800, 1000.  The general 
solution to this system is<PRE>     z<sub>i</sub>- B<sub>i</sub>/[1 + C<sub>i</sub> exp(B<sub>i</sub>t)]</PRE>

<P>If the initial values are z<sub>i</sub>(0) = -1 then C<sub>i</sub> = -(1+B<sub>i</sub>)

<P>This problem is phrased in FC as follows:

<b><PRE>
       PROBLEM KROGH (5000,1000,1000)
      COMMON /KROG/ Z(4),ZDOT(4),T,DT,TF
      Z(1)=-1 : Z(2)=-1.0 : Z(3)=-1.0 : Z(4)=-1.0
      T=0.0 : DT=.5 : TF=1.0
      INITIATE MERCURY(SETUP); FOR STIFF;
     ~    EQUATIONS ZDOT/Z; OF T; STEP DT; TO TF
      INTEGRATE STIFF; BY MERCURY
      REWIND 98
      PRINT 5
5     FORMAT('      TIME        Z1        Z2')
      DO 10 I=1,100
        READ (98) TIME,Z1,Z2,Z3,Z4
       PRINT 6,TIME,Z1,Z2,Z3,Z4
6     FORMAT(3E14.6)
10   CONTINUE
     END
     CONTROLLER SETUP(MERCURY)
       ERRMAX=1E-6
       STIFF=1
       SAVE=0.01
     END
     MODEL STIFF
     COMMON /KROG/ Z(4),ZDOT(4),T,DT,TF
     DIMENSION B(4)
     DATA B/-10.0,0.001,800,1000/
     DO 10 I=1,4
       ZDOT(I)=Z(I)*(Z(I)-B(I))
10   CONTINUE
     END

OUTPUT:
    TIME          Z1             E2
 [FIX. FILL IN OUTPUT]
</PRE>
</b>

<h2>Propagating Solvers</h2><P>Integration solvers which propagate partial derivatives may be employed 
in any context in a FC program.  However, as derivative propagation 
requires significant computation overhead, these solvers are not recommended 
for use in contexts where derivative evaluation is not active. 
<h3>Solver ISIS</h3>
<P>ISIS is a fourth order Runge-Kutta method, employing the Gill technique 
for error control.  In general, Runge-Kutta methods are known as "single-step" 
or "self-starting" techniques, since each step is independent of the 
last, just as though each represented a new initial value problem.  The 
Gill modification considerably reduces numerical error, but it does 
so by "remembering" error correction terms as the integration progresses.  Thus, 
the technique represented by ISIS must be viewed as having a memory, 
analogous to the predictor-corrector memory of solver JANUS.

<P>The calculus model, representing the differential equations for ISIS, 
may contain any calculus processes, including integrations involving 
ISIS.  There are no controls for ISIS and it employs no parameters.

<P><B><I>Initiating ISIS</B></I>-  The INITIATE statement for ISIS has the 
following form

<P><B>INITIATE  ISIS; FOR</B> <i>model</i><B>; EQUATIONS 
</B>  
<I>ode/vars<B>;</B></I><B><br>OF </B> <I>ind-var</I><B>; STEP</B> <I>delta</I><B></B>; <b>TO</b> <I>limit</I>
<P>The meaning and form of the symbols <I>model</I>, <I>ode/vars</I>, 
<I>ind-var</I>, <I>delta</I> and <I>limit</I> are identical to those 
described for integration processes in Sections 1.3 and 2.2.1

</b></b>
<h3>Examples</h3>

<B><PRE>INITIATE  ISIS; FOR MOD2; EQUATIONS A/B, C/D; 
     OF  INDEP;  STEP INC;  TO XFINAL

INITIATE  ISIS; FOR  DEQS;EQUATIONS VECD/VECV
     OF ZZ;  STEP DELZZ; TO  ZZEND
       </PRE>
</b>

<P><B><I>Executing ISIS</I></B>  -  
Once the INITIATE statement has been executed, 
the integration may be performed by execution of:

<P><B>INTEGRATE</B> <I>model</I>; <B>BY ISIS</B>

<P>where <I>model</I> is the MODEL label identified in the INITIATE statement.

As with all step-by-step calculus processes, ISIS produces no printed 
output.  If values at the end of a step are required, they must be 
generated by ordinary FORTRAN output statement.  See the example in 
Section 5.1 for an approach to step printing.

Because of the Gill modification, ISIS must be reinitiated whenever 
the value of any dependent variable or the independent variable is 
modified.  Failure to do so will disable the error control mechanism 
and, in fact, may cause it to be counterproductive.  It is doubly 
critical to do this in circumstances in which derivative evaluation 
is in progress, since the resulting discontinuities in derivatives 
may have disastrous consequences. In particular, when ISIS is nested 
within a calculus process which activates derivative evaluation, such 
as AJAX, the INITIATE and INTEGRATE statements must both be placed 
within the nested model.  Examples of proper usage in the case of 
combined calculus processes are given later in this section.

<P><B><I>Terminating ISIS</I></B>  -  When the integration process has reached 
the desired solution, it may be terminated by
<P><B>TERMINATE</B> <I>model</I>
<P>This terminates ISIS for the model being integrated.  (Other models 
which ISIS might be integrating remain unaffected.)

The significance of terminating ISIS is that the integration variables 
are released from preemption, the model is freed for use in other 
calculus processes, and dynamic storage used by the process is released.  When 
ISIS is nested within an iterative process, TERMINATE must be used 
to prevent the multiplicative use of dynamic storage.
<h3>Solver JANISIS</h3> 

JANISIS is a hybrid solver which executes identically to solver ISIS 
when derivative evaluation is active and identically to the solver 
JANUS otherwise.  In all respects, the descriptions of ISIS and JANUS 
apply to JANISIS.  In particular, the control variables of JANISIS are 
those of JANUS (ISIS has no control variables.)

This solver is more efficient than ISIS when nested within calculus 
processes employing solvers (such as AJAX) which execute their models 
with derivative evaluation both active and inactive.

<h2>The Integration Model</h2>

The calculus model representing the ODEs must contain both the equations 
themselves and any auxiliary calculations required for their computation.  These 
equations may be computed in any logical sequence.  In addition, they 
may be computed either in the MODEL procedure or in any subsidiary 
MODEL or FMODEL which it executes. However, the MODEL referenced in 
the INITIATE and INTEGRATE may not have parameters.

While it may be obvious, it should be noted that the integration variables 
used by the model must be global variables, since they are shared 
by the model, the solver, and the program unit in which the calculus 
process appears.  It may be necessary, therefore to include these 
variables in appropriate common blocks.&nbsp; 

<h3>Example</h3>

Consider a projectile drag force F<MV>D<D> which is a function of 
the projectile velocity V, according to the following formula

<br>

<br>&nbsp;&nbsp;&nbsp;&nbsp; F<sub>D</sub> = F<sub>D</sub> RHO V<sup>2</sup>/2</li

 If F<MV>&nbsp;&nbsp;&nbsp;&nbsp; If F<sub>D</sub><D> is employed in the differential equation&nbsp;&nbsp;&nbsp;&nbsp; 
[FIX. convert RHO to symbol]
<br>
<br>&nbsp;&nbsp;&nbsp;&nbsp; m dV/dt = -F<sub>D</sub> cos THETA
       
<br>
       
<br>then the equation for F<MV>D<D> must be included in the model block 
as an auxiliary equation.  
Thus <B><PRE>MODEL PROJECT 
<N>  COMMON/DRAG/FD,DVDT,CD,RHO,V,THETA,AMASS<br>  FD = CD*RHO*V**2/2
  DVDT = - FD*COS(THETA)/AMASS
END
</PRE>
</b>
In general, the model will be executed more than once per integration 
step.  Thus, it is desirable to exclude from the model all calculations 
which are not essential to the ordinary differential equations themselves.

<h2>Higher Order Differential Equations</h2>

The integration of higher order ODEs (second order, third order, etc.) 
may be accomplished with any integration solver without reducing the 
equations to a normal system.

As a basis for discussion, consider a set of two simultaneous first 
order equations:
<br>dy/dt = x  -  y

Choosing obvious names, the INITIATE statement for this problem might 
be:

<P><B> INITIATE  ISIS; FOR TWO;<N>EQUATIONS  XP/X, YP/Y;
 <br>OF T; STEP DT; TO TF</b>
<P>Thus, XP is specified to be the first derivative of X with respect 
to T:
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; XP = dX/dT

<P>Now suppose that, instead, there was the single second order equation

<P>&nbsp;&nbsp;&nbsp;&nbsp; d<M^><sup>2</sup><D>x/dt<M^><sup>2</sup><D> = 2x

<P>then, clearly, there must be an integration variable to represent 
the second derivative, which might be names XPP:<P>&nbsp;&nbsp;&nbsp;&nbsp; XPP = d<M^><sup>2</sup><D>X/dT<M^><sup>2</sup> = d/dT (dX/dT)  = dXP/dT
<P>Thus, to fully specify the variables for this equation in an INITIATE 
statement, it must take the form:
<P><B>INITIATE  ISIS; FOR DOUBLE ;<N>EQUATIONS XPP/XP,XP/X;<br>
 OF T; STEP DT; TO TF

</b>
<P>where, by analogy, XPP is interpreted as the first derivative of XP 
with respect to T and XP is interpreted as the first derivative of 
X with respect to T.  Note that the form of the specifications requires 
a name for XP even though it may not actually appear in the second 
order equation.

The preceding discussion may be generalized as follows.  For each 
<I>n</I>th order equation, the <I>n</I> derivatives must all be assigned 
names and there must be an entry in the ode-vars list for each one.
<h3>Example</h3><P>The fifth order equation: </b>
<P>&nbsp;&nbsp;&nbsp;&nbsp; d<sup>5</sup><D>y/dt<sup>5</sup><D> = 3t<sup>2</sup> <D>+y<sup>3
</sup>
<P>may be integrated be first initiating JANUS by:

<P><B>INITIATE  JANUS;  FOR  ORDER5;
<br>EQUATIONS D5Y/D4Y,D4Y/D3Y,D3Y/D2Y,D2Y/DY,DY/Y;
<br>OF T; STEP DT; TO TF</b><p>and then by executing
<P><B>INTEGRATE ORDER5; BY JANUS

</b>
<P>using the model <B> <br>
<br>MODEL ORDER5
<br>COMMON/DERS/D5Y,D4Y,D3Y,D2Y,DY,Y,T
<br>D5Y = 3*T**2 + Y**3
<br>END
</b>
<P>As usual with the integration solvers, all dependent variables must 
be set to their initial values before the INITIATE  statement is executed.  In 
the above example, D4Y,D3Y,D2Y,DY, and Y must all be initialized, 
in addition of course to T,  DT and TF.  (As noted in the introduction 
to Section 5, a fifth order initial value problem requires five initial 
conditions to specify a unique solution.)

Where the problem involves simultaneous equations, of any order, the 
same approach is used to specify all of the pertinent derivatives 
and variables.  For three simultaneous equations, of first, second, 
and third order respectively, there would be a total of six pairs 
of derivative/variable sets in the <I>ode-vars</I> list.

</b>
<h3>Example</h3>

For the simultaneous equations<P>&nbsp;&nbsp;&nbsp;&nbsp; d<sup>3</sup>y/dt<sup>3</sup> = 
xy<br>&nbsp;&nbsp;&nbsp; d<sup>2</sup>x/dt<sup>2</sup>&nbsp; = xt

<P>The INITIATE statement could be written

<P><B> INITIATE  ISIS  FOR  MIXED;
 <br>EQUATIONS   D3Y/D2Y, D2Y/DY, DY/Y, D2X/DX, DX/X;
 <br>OF T;  STEP DT;  TO TF

</b>
<P>All of the preceding examples illustrate a systematic specification 
of the higher order derivatives: they appear in sequence, from high 
to low.  This is not optional.  The integration solver requires this 
discipline in order to perform its internal reduction.
<P>If the variables in the list are vectors, then each element of a higher 
order derivative vector must be the first derivative of the corresponding 
element of its succeeding vector, in complete analogy to the scalar 
form.

</b>
<h2>Implicit Differential Equations</h2><P>An implicit ordinary differential equation cannot be reduced to the 
normal form

<P>&nbsp;&nbsp;&nbsp;&nbsp; y<F128M>&#39; = f(x, y)      

<P>but rather has the general form<P>&nbsp;&nbsp;&nbsp;&nbsp; g(x, y, y<F128M>&#39;<F255D>) = 0

<P>Systems of such equations, which may involve higher order derivatives, 
are solved in FC by a combined calculus process.  The integration 
process is executed exactly as if the model involved explicit equations.  Within 
the model, however, the equations are actually calculated by a general 
algebraic equation solver, such as AJAX.

<P>As far as the specification of the integration process is concerned, 
there is absolutely no difference between the solution of implicit 
and explicit equations.  In a given model, in fact, some equations 
may be implicit while others are explicit.  The calculus model itself, 
of course, is quite different, reflecting the different character 
of the mathematics.

<P>Any FC integration solver may be used to solve implicit equations 
and all of the preceding discussions of integration apply to such 
equations.  The preferred solvers, however, are JANUS and MERCURY 
since the fact that they execute the model only twice per integration 
step provides a very significant computational efficiency.

<P>The procedure involved in solving this combined process is best described 
in terms of the following representative example.  For descriptions 
of the solvers employed, refer to appropriate sections of this manual.

<h3>Example</h3><P>The implicit differential equations:

<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dx/dt + [1+(dx/dt + dy/dt)/(x+y)] <sup>1/2</sup><D> = 0

<P>&nbsp;&nbsp;&nbsp;&nbsp; dy/dt + [1+(dx/dt + dy/dt)/(x+y)] <sup>1/2</sup><D> = 0

<P>may be solved by the following program
<b>
<pre>PROGRAM IDE
  COMMON/IMP/DXDT,X,DYDT,Y 
  READ *,X,Y,DYDT,DYDT ! Initial conditions and initial guesses 
  READ *,T,DT,TPRINT,TFINAL 
  INITIATE JANUS; FOR DEQ; 
    EQUATIONS DEDT/X,DYDT/Y; OF T; STEP DT; TO TF 
   TF = TPRINT/10 
   DO WHILE (TF.LT.TFINAL) 
      INTEGRATE DEQ; BY JANUS 
      PRINT *,T,DXDT,X,DYDT,Y 
     TF=TF+TPRINT 
   END DO 
END 

CONTROLLER SET (AJAX) 
   SUMMARY=0 
END 

MODEL DEQ 
  COMMON/IMP/DXDT,X,DYDT,Y 
  FIND DXDT,DYDT; IN IDE(GX,GY); BY AJAX(SET); TO MATCH GX,GY 
END 

MODEL IDE(GX,GY) ! IMPLICIT EQUATIONS 
  COMMON/IMP/DXDT,X,DYDT,Y 
  RAD=SQRT(1+(DXDT+DYDT)/(X+Y)) 
  GX=DXDT+RAD 
  GY=DYDT+RAD 
END </pre></b>

<h2>Rational Function Extrapolation (RFE) Solvers</h2>

The following three solvers, NEPTUNE, MERLIN, and GEMINI employ the 
technique of rational function extrapolation developed by Gragg, Bulirsch, 
and Stoer: 
<UL>
<LI>
<P>The following three solvers, NEPTUNE, MERLIN, and GEMINI employ the technique 
of rational function extrapolation developed by Gragg, Bulirsch, and Stoer:

<UL>
<LI>Bulirsch and Stoer, "Numerical Treatment of Ordinary Differential 
Equations by Extrapolation", Numerische Mathematik 8, 1-13 (1966).<br><br></LI>
</UL>

This method, like that of MERCURY, optimizes both the step-size and 
the order of approximation so as to minimize the computation necessary 
to satisfy a given error bound.  These solvers offer significant advantages 
in controlling the local truncation error and in determining an appropriate 
step-size dynamically over the range of integration, and can provide 
considerable time savings for lengthy integrations.

In contrast to MERCURY, however, the RFE solvers also provide the 
following benefits:<br><br>
	<UL>
		<LI>They do not invoke the evaluation of partial derivatives.</LI>
		<LI>They usually require fewer model evaluations when very  precise 
results are mandated.  For error bounds smaller  than about 1.0E-8, 
the savings over Runge-Kutta or Adams  methods can be from a factor 
of 2 to as much as 30.  While  MERCURY provides similar advantages, 
as the error bound  drops the superiority of RFE becomes more pronounced.</LI>
		<LI>They are self-starting so that the full power of the method  is 
applied over the entire range of integration.<br><br></LI>
	</UL>

The RFE solvers are memory solvers, i.e. each INTEGRATE  statement 
uses information generated at a preceding INTEGRATE (if any). Thus, 
a change in any of the key variables except the step-size and integration 
limit demands re-initiation of the solver.  For example, if a differential 
equation has a discontinuity then the solver must be halted and re-initiated 
at this point.  (This is a restriction for all memory solvers, i.e. 
for all integration solvers except MINERVA, ATHENA, and PEGASUS.)  When 
there are numerous discontinuities, PEGASUS offers a better method 
for error control and step-size management.

	<li><br></li>
	The three RFE solvers NEPTUNE, MERLIN, and GEMINI are distinguished 
only in the way they operate in combination with other calculus processes:<br><UL>
		<LI>NEPTUNE is a straight FORTRAN implementation of the RFE 
algorithm, which does not propagate partial derivatives</LI>
		<LI>MERLIN is an overloaded implementation of the RFE algorithm 
designed to propagate partial derivatives</LI>
		<LI>GEMINI is a hybrid of the two designed to operate as MERLIN 
when partial derivative evaluation is active and to operate as NEPTUNE 
when it is not.</LI>
	</UL>
<h3>Solver NEPTUNE</h3>

The following description of NEPTUNE applies equally to MERLIN and 
GEMINI.

	<P><b><i>Initiating NEPTUNE</i></b> - The INITIATE statement for NEPTUNE takes 
the form:

	<P><strong>&nbsp;&nbsp;&nbsp;&nbsp; INITIATE NEPTUNE<em> </em></strong>{(<em>controller</em>)}; 
	<strong>FOR</strong> <em>model</em>;  <strong>EQUATIONS</strong> o<em>de/vars</em>;<BR>
	<strong>&nbsp;&nbsp;&nbsp;&nbsp; OF</strong> <em>ind-var</em>; <strong>STEP</strong>
	<em>delta</em>; <strong>TO</strong> <em>limit </em>
	<P>The meaning and usage of the elements of this statement are identical 
to those described for MERCURY in section 5.1.

	<P>Contolling NEPTUNE - NEPTUNE has three control variables, all 
concerning step size control, as follows :<br>&nbsp;<table style="width: 100%" class="style6">
		<tr>
			<td>Variable&nbsp;</td>
			<td>Description&nbsp;</td>
			<td>Preset Value&nbsp;</td>
		</tr>
		<tr>
			<td>ERRMAX&nbsp;</td>
			<td>&nbsp;ERRMAX Relative error limit&nbsp;.<br>The order of 
			approximation and step-size are 
	<R>adjusted to assure that the largest relative local<R>
		truncation error does not exceed ERRMAX, i.e.<R>
		MAX(ABS(YERROR/Y) < ERRMAX </td>
			<td>0.0001&nbsp;</td>
		</tr>
		<tr>
			<td>STEPMAX&nbsp;</td>
			<td>STEPMAX Maximum allowed step-size.<br>The preset value provides 
			effectively no limit. If the 
	<R>equations are potentially unstable, some appropriate 
	<R>upper bound on the step is advisable.

	</td>
			<td>10<sup>9</sup>&nbsp;</td>
		</tr>
		<tr>
			<td>STEPMIN&nbsp;</td>
			<td>STEPMIN Minimum allowed step-size. &nbsp;<br>This control is provided 
			as a protection against 
	<R>modeling errors or a choice of ERRMAX which is<R>
		incompatible with the differential equations. If error 
	<R>control requires a step smaller than this value, 
	<R>integration halts with a fatal error diagnostic. 
	<R>Do not use this control in an attempt to disable<R>
		step-size management.

	</td>
			<td>10<sup>-9&nbsp;</sup></td>
		</tr>
	</table>
	<P>The following considerations concerning the step-size, delta, 
should be noted :

	<UL>
		<LI>NEPTUNE adjusts the value of  delta after completing  execution 
of the INTEGRATE statement so that subsequent  integrations may proceed 
from an optimal step-size.   Interference with this judgment by altering 
the value of delta is allowed but is discouraged.<br></LI>
		<LI>The significance of the initial value of delta is 
quite  different from the cases of MERCURY and PEGASUS, both of  which 
apply unique strategies for improving the step-size.   In the case 
of PEGASUS, the initial value is considered to  be valid estimate 
and any adjustments are relatively  conservative.  MERCURY treats 
the initial value as a tentative lower limit for its iterative 
improvement and  thus the value is not too critical and should always
be  selected on the low side (perhaps by 1 or 2 orders of  magnitude).<br><br>In 
direct contrast, NEPTUNE treats the initial  value as a staring point 
for its extrapolation to the  limit.  While it can adjust to larger 
staring values as it  progresses, the increase is likely to be conservative, 
and  thus the initial value should be chosen on the high side  (by 
about the same 1 or 2 orders of magnitude).</LI>
	</UL>

<h3>Solver MERLIN</h3>

The only difference between MERLIN and NEPTUNE is that MERLIN has 
the additional capability to propagate partial derivatives and thus 
may be used in nested calculus processes, such as boundary value problems.  In 
all other respects, the description of NEPTUNE.  Both solvers have 
the same control variables and invoke the same integration techniques. 
The additional capability, however, is achieved at a cost of slower 
execution speed.  thus, unless derivative evaluation is in progress, 
NEPTUNE should always be used in preference to MERLIN.<H3>Solver GEMINI</H3>

GEMINI is a hybrid solver, analogous to JANISIS and with similar applications.  When 
GEMINI is initiated, the method of either MERL.IN or NEPTUNE is selected 
according to whether derivative evaluation is currently in progress 
or not, respectively.  This solver is thus the ideal choice when the 
NEPTUNE/MERLIN technique is needed within a nested calculus process, 
for example when solving boundary value or optimal control problems.  Most 
calculus solvers (in particular AJAX, MARS, JOVE, ZEUS, and JUPITER) 
execute their models both with and without derivative evaluation during 
their optimization iterations. Thus, using GEMINI rather than MERLIN 
will allow the much faster NEPTUNE to be used whenever possible.

The alternate hybrid solver, JANISIS, is usually less effective than 
GEMINI in both precision and speed.  Thus, GEMINI is preferable unless 
single-step integration is essential.  The distinctions between single-step 
and memory solvers are discussed in Section 5.8.
	<h2>Solvers for Limiting Integration</h2>

Limiting is the process of imposing constant bounds on the values 
of the dependent (state) variables of integration.  The limiting technique 
is a "shooting method" which terminates integration at the precise 
limit value by suitable step-size adjustments.  At this limiting point, 
the FC program is free to adjust the limits and/or change the differential 
equations, for example by holding the limited variable to a constant 
value.

The use of limiting is restricted to single-step integration solvers, 
i.e., those which retain no "memory" of previous steps in the integration 
method.  Such solvers include PEGASUS, MINERVA, and ATHENA, described 
below.

Applications of limiting include the following :<br>&nbsp;<UL>
		<LI>Physical Discontinuities - The system being modeled 
may have discontinuities, at which  points the characteristics of 
the differential equations  change, for example clipped transmission 
waves, trajectory  impact point, chemical phase transitions, and mechanical  limiters.  In 
each of these cases, the equations may be  integrated to the discontinuity 
and then suitable logic  flags may be set so that the model will select 
alternate  computations during the following integration.  A variation  of 
this application is where the properties of the system  change during 
the course of integration, such as a resource  becoming exhausted 
or a transition from subsonic to  supersonic flow.<br><br></LI>
		<LI>Variable Termination Criteria - In some problems, 
the end point of integration is defined  in terms of a dependent variable 
value.  The most typical  examples are pursuit problems and models 
involving resource  management.  These are handled as described for  discontinuities, 
the only difference being that the  solution is complete when the 
limit is reached.<br><br></LI>
		<LI>Arbitrary Interruptions  - Often it is desirable 
to interrupt integration when  dependent variables reach prescribed 
values simply to  perform peripheral functions.  The most common example 
is  where output information must be printed or plotted.<br><br></LI>
	</UL>

There are two types of limiting, normal and absolute, 
selectable by setting an appropriate solver control variable.  In 
the normal (default) case, the limit tests are performed only at the 
end of each step and, therefore, any sub-step model evaluations may 
involve out-of-bounds values.  (Most solvers require sub-step evaluations.) 
For many cases this is acceptable, and whenever possible this mode 
should be used.

<br><br>Absolute limiting applies the tests for every model evaluation and 
thus removes all possibility of variable excursion. The most common 
need for this arises when an out-of-bounds value will cause a mathematical 
error such as a negative square root.  (In choosing between absolute 
and normal limiting, a special case should be noted.  Contrary to 
what might be thought, absolute limiting can actually be much more 
efficient than normal limiting when the step size is large.)<br><br>Limiting, and particularly absolute limiting, can be a fairly time-consuming 
process.  Thus it is desirable to use it only when it is required.  If 
it is known that, once a limit is reached, subsequent integration 
may be unconstrained, a good approach is to re-initiate integration 
at this point without limiting.  Although this has the same effect 
as simply resetting the limits to "infinity", the net result will 
usually be greater efficiency.
	<H3>Solver MINERVA</h3>
	<P>Integration solver MINERVA has the following distinguishing features:

	<UL>
		<LI>It employs a true single-step integration method, with no  use 
whatsoever of information from prior steps.  This has  several important 
consequences, described in Section 5.8.<br></LI>
		<LI>It offers Runge-Kutta methods of orders 2, 3, 4, and 5.   The 
first three of these options are special formulations  designed to 
minimize the local truncation error, i.e. the  principal part of the 
error incurred in one step.  The  fifth order method offers both high 
precision and an  extended domain of stability.<br></LI>
		<LI>Limits may be imposed upon the dependent variables of  integration.  The 
applications of such limits and examples  of their use are described  below.  These 
examples  should be carefully reviewed before using the limiting  feature.<br></LI>
		<LI>Like solver MERCURY, MINERVA does not propagate partial 
derivatives. thus, it may not be used within a calculus process which 
activates derivative evaluation.  (For problems requiring derivatives, 
refer to integration solver ATHENA, described in Section 5.7.2.)</LI>
	</UL>
	<P><strong>Initiating MINERVA</strong> - The INITIATE statement for MINERVA is:

	<P><strong>INITIATE  MINERVA{(</strong><em>controller)</em><strong>}; 
{WITH FLAG </strong><em>signal</em><strong>;} <BR>{{AND|WITH} LOWER{S} </strong>
	<em>bottoms</em><strong>;} {{A<em>ND|WITH} 
UPPER{S} </em></strong><em><strong>tops</strong></em><strong><em>;}<BR>FOR </em>
	</strong><em><strong>model</strong></em><strong><em>; EQUATIONS </em>
	</strong><em><strong>ode/vars</strong></em><strong><em>; OF ind-var</em>; 
	STEP </strong><em>delta</em><strong>; TO</strong><em> limit </em>

	<P>With the exception of the clauses pertaining to limiting, the meaning 
and use of the elements of this statement are identical to those described 
for JANUS in Section 5.1.1.  As usual,  the optional clauses may be 
input in any order.  The remaining mandatory  clauses must be given 
in the prescribed sequence.

	<P>The UPPERS and LOWERS clauses permit the imposition of limits, i.e. 
fixed bounds upon the dependent (state) variables.  Either or both 
types of limits may be used; but if a given type is present, there 
must be a limit for every dependent variable.  This is required because 
each entry in the list of limits is associated with its dependent 
variable by matching the bottoms or tops  list with 
the ode/vars list in a left-to-right order.  As usual with 
lists of variables in INITIATE statements, the bottoms and 
tops must be variables (not constants) and they may be any 
combination of scalars, array elements, array parts and entire arrays.  For 
the purpose of association, list entries taken from arrays are extracted 
column by column.

	<P>Sample INITIATE statements are:

	<b><PRE>
	INITIATE  MINERVA;  WITH UPPER HIVAL;  AND FLAG TESTF;        
	     FOR ONE;  EQUATION DY/Y;  OF T;  STEP DT;  TO TFINAL
	
	INITIATE   MINERVA(SETUP);  WITH UPPERS HI1,HI2;                       
        AND LOWERS LO1,LO2;  FOR TWO; EQUATIONS DE/A,DB/B;         
	    OF C;  STEP DELC;  TO ENDC
	    
	INITIATE MINERVA; FOR MANY; EQUATIONS DV/V;                      
	     OF T; STEP DELTA; TO TF  
	</PRE> </B>                                        
	<D>
	<P>The optional flag may be used to determine which equation was limited.  After 
the integrate statement has been executed, the flag variable will 
have a value of zero if there was no limiting required while integrating 
up to limit.  Otherwise, it will contain the number of the 
equation which required limiting, counting from left to right in the 
ode/vars list.  If limiting is not imposed, the flag is ignored 
and its value will remain unchanged.  When two variables limit simultaneously, 
the leftmost one in the ode/vars list is flagged.

Controlling MINERVA - The control variables for MINERVA are:<br>&nbsp;<table style="width: 100%" class="style6">
		<tr>
			<td style="height: 26px">Variable&nbsp;</td>
			<td style="height: 26px">Description</td>
			<td style="height: 26px">Preset Value</td>
		</tr>
		<tr>
			<td>EPSILON&nbsp;</td>
			<td>EPSILON limiting convergence criterion.<br>If the equations are 
			integrated to a point at 
	<R>which any further steps would be less in 
	<R>absolute magnitude than EPSILON, then the 
	<R>limit has been reached and integration halts.<R>
		If EPSILON is zero, then it is automatically<R>
		set to the input step size times 0.001.

			&nbsp;</td>
			<td>0.001&nbsp;</td>
		</tr>
		<tr>
			<td>BOUND&nbsp;</td>
			<td>BOUND Type of limiting option.<br>&nbsp;Zero selects normal limiting 
			and nonzero 
	<R>selects absolute limiting.</td>
			<td>0&nbsp;</td>
		</tr>
		<tr>
			<td>ORDER&nbsp;</td>
			<td>ORDER Selector for the Runge-Kutta order.<br>The formulations 
			are Heun (Order 2), 
	<R>Kuntzmann (orders 3 and 4), and

			Lawson (order 5).</td>
			<td>3&nbsp;</td>
		</tr>
	</table>

	<P>The following examples illustrate two common uses of limiting. <h3>Examples</h3>
	The first example is a system of two equations representing a growth/decay model in which the growth curve 
	has an upper limit.<br><br>&nbsp;&nbsp;&nbsp;&nbsp; dy<sub>1</sub>/dt = y<sub>1</sub>
	<br>&nbsp;&nbsp;&nbsp;&nbsp; dy<sub>2</sub><D>/dt = -y<sub>2 </sub><br><br>where y<MV>1<D> has a maximum value of 5.  The analytical solution 
of these equations is y<MV>1<D>=exp(t) and y<MV>2<D>=exp(-t).  This 
system may be integrated from t=0 to t=10 by the following program:

<b>
	<pre>PROBLEM DEMO
  COMMON DY1,Y1,DY2,Y2,TLIM
  Y1=1 : Y2=1<N>                   !Establish initial conditions
  T=0 : TLIM=0.0 : DT=0.05 : TFINAL=10 : HY1=5 : HY2=1E10

  INITIATE MINERVA; WITH UPPERS HY1, HY2; FOR SYSTEM;
 ~    EQUATIONS DY1/Y1,DY2/Y2 OF T; STEP DT; TO TFINAL

  INTEGRATE SYSTEM; BY MINERVA

!   Now test if a limit occurred before TFINAL

  DO WHILE (T.LT.TFINAL)
    TLIM=T                       ! Set up new model conditions
    INTEGRATE SYSTEM; BY MINERVA ! and finish integration
  END DO
!   Generate final output
  PRINT *,'Y1=',Y1,'Y2=',Y2,'AT T=',T

  IF (TLIM.NE.0.0) THEN
    PRINT *,'Y1 LIMITED AT T=',TLIM
  ENDIF
END

MODEL SYSTEM
  DY2=-Y2
  IF (TLIM.EQ.0.0) THEN
    DY1=Y1
  ELSE
    DY1=0
  ENDIF
END
</pre>
	</b>The output of this program is :
<b>
	<pre>Y1 = 5.00E+00 AND Y2 = 4.54E-05 AT T = 10.00
Y1 LIMITED AT T = 1.61
</pre>
	</b>
	<P>Note how the limits were imposed.  Whenever there are any limits, 
they must be given for every equation.  In this case, the limit for 
y<MV>2<D> was set essentially at infinity.
	<P>The second example is a modification of the first in which limiting 
is also used to obtain output information at prescribed values of 
one of the dependent variables, i.e. at each decade drop in y2.  For 
this case, lines 5 through 12 are rewritten as follows:
<b><pre>
INITIATE MINERVA; WITH UPPERS TOP1,TOP2; AND LOWERS BOT1,BOT2;
   WITH FLAG PICK; FOR SYSTEM; EQUATIONS DY1/Y1,DY2/Y2;
   OF T; STEP DT; TO TFINAL 
   
BOT1=1E-9 : BOT2=0.1

DO WHILE (T.LT.TFINAL)
  INTEGRATE SYSTEM: BY MINERVA
  IF(PICK.EQ.1.0) THEN ! Limit stop on Y1
    TLIM=T
  ELSEIF(PICK.EQ.2.0) THEN  ! Print stop on Y2
    BOT2=BOT2/10.0
  ENDIF
END DO

</pre>
	</b>
	The output of the modified program then becomes:
<b>
	<pre>Y1 = 5.00E+00 AND Y2 = 1.00E-01 AT T =  2.30
Y1 = 5.00E+00 AND Y2 = 1.00E-02 AT T =  4.61
Y1 = 5.00E+00 AND Y2 = 1.00E-03 AT T =  6.91
Y1 = 5.00E+00 AND Y2 = 1.00E-04 AT T =  9.21
Y1 = 5.00E+00 AND Y2 = 4.54E-05 AT T = 10.00
Y1 LIMITED AT T = 1.61

</pre>
	</b>
	<P>A final example shows how "constant" limits may be generalized by 
introducing additional dependent variables.  In a pursuit problem, 
the two independent trajectories are integrated until the vehicles 
are 'close', at which time the pursuit phase is over.  A program which 
solves this problem is:<b><pre>PROBLEM PURSUIT<br>   COMMON/VARS/Y1,Y2,Y3,DY1,DY2,DY3
  DIMENSION FLOOR(3)<br>&nbsp; DATA FLOOR/-1E200,-1E200,0.005/&nbsp; ! Set lower limit on Y3=Y2-Y1<br>		<br>&nbsp; Y1=0: Y2=2: Y3=2: T=0: DT=0.5: TF=10&nbsp; ! Set initial conditions
		<br>&nbsp; INITIATE MINERVA; WITH LOWERS FLOOR; FOR CHASE;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ~&nbsp;&nbsp;&nbsp; EQUATIONS DY1/Y1,DY2/Y2,DY3/Y3; OF T; STEP DT; TO TF<br>&nbsp;&nbsp;INTEGRATE CHASE; BY MINERVA&nbsp; ! Until Y3 reaches limit<br>END
	<br>MODEL CHASE <br>&nbsp; COMMON/VARS/Y1,Y2,Y3,DY1,DY2,DY3<br>&nbsp; DY1=1+Y1 ! Solution is Y1=EXP(T)-1<br>&nbsp; DY2=1-Y2 ! Solution is Y2=EXP(-T)+1<br>&nbsp; DY3=DY2-DY1 ! Solution is Y3=Y2-Y1<br>END<br>	</pre>
	</b>
	<P>The result is:<P>&nbsp;PROXIMITY=0.0050 AT T=0.8796</B>

	<P>Some points to remember while using limiting are as follows: 
	<LI>When limiting is required for some equations and not for  others, 
there are two feasible approaches.  The required  limits are defined 
for the constrained equations and for  the remainder either:<UL>
		<LI>use a limit which is completely out-of-range of the  equations, 
or
		<LI>use both upper and lower limits and overlap them.  In  this 
case they will be ignored.
	<br>
	<br>
	</UL>
	</LI>
	<LI>The values of the limit variables may be changed between executions of 
	the INTEGRATE statement without any requirement to re-initiate the solver. 
	However, the limit variable cannot be changed in the integration model 
	itself i.e. the value when the INTEGRATE statement is executed prescribes 
	the limit.<br><br><LI>When a limit is reached, integration halts with the 
	limited variable set slightly below the upper limit (or above the lower 
	limit). How near it is depends upon the solver control variable EPSILON, but 
	it will usually be within 0.0001 relative at the preset value. If a variable 
	is set exactly to the limit, subsequent integration will promptly halt, 
	flagging that a limit has been reached. Thus, never set a variable precisely 
	to the limit i.e. always a small amount away (at least 10).<br></LI>
	<li>If any variable has an out-of-range initial condition,  integration 
cannot proceed and a fatal execution error  occurs (with a suitable 
diagnostic).  Hence, when  initiating integration on the basis of 
calculated  conditions, as in a boundary value or optimal control  problem, 
always make limit tests before attempting to  proceed.<br></LI>
	<LI>The "current" step size after a limit is reached is the 
value before the specially reduced step required to move to  the limit.</LI>

	<h3>Solver ATHENA </h3>
<p>
Integration solver ATHENA is identical to MINERVA in all but one respect.  ATHENA 
has the additional capability to propagate the evaluation of partial 
derivatives and thus may be nested within calculus processes, for 
example in boundary value or process identification problems.  In 
all other respects, the description of MINERVA applies equally to 
ATHENA.  Both offer the same options, have the same control variables, 
and invoke the same integration techniques.  the additional capability 
of ATHENA, however, is achieved at a cost of slower execution speed.  Thus, 
unless derivative evaluation is in progress, MINERVA should always 
be used in preference to ATHENA.
	<p>
	One point which bears particular emphasis is that, if ATHENA is nested 
within a calculus process, its INITIATE statement should not be executed 
within the calculus model.  Instead it should be performed before 
the calculus process is begun.  This is the exact opposite of the 
rule for ISIS, which is one key reason why ATHENA is more efficient 
than ISIS.
	<h3>Solver PEGASUS</h3>
	<p>Integration solver PEGASUS provides special features for evaluating 
and modifying the step-size so as to hold local truncation error below 
a specified limit.  This capability, like that of JANUS and MERCURY, 
avoids the use of overly conservative step sizes as a protection against 
unacceptable errors and thus normally permits more efficient integration.  It 
is also very useful for a system of differential equations with varying 
characteristics over the range of integration, for example a transient 
fluctuation followed by a decay to a steady-state condition.  In such 
cases, the appropriate step-size would be quite different over the 
two regions and PEGASUS can make the necessary adjustments.

PEGASUS employs a special 5th order Runge-Kutta technique known as 
Sarafyan Embedding, in which a 4th order result is obtained at the 
same time.  The difference between the two is used to estimate the 
error.  This approach has the unique property that error evaluation 
is performed without extra model evaluations.  The net effect is a 
step-size control method which approaches the accuracy and efficiency 
of the predictor-corrector methods of MERCURY and JANUS.

When step-size control is the only factor of importance in a problem, 
then either MERCURY or NEPTUNE is far preferable to PEGASUS.  On the 
other hand, PEGASUS offers two special features:

	<UL>
		<LI>It permits limiting of the dependent variables.  Examples  and 
applications of the use of limiting are described in  detail in Section 
5.71;</LI>
		<LI>It employs a true single-step method, which allows a degree  of 
flexibility beyond that of memory methods.  This point and its consequences 
are discussed in Section 5.8.<br></LI>
	</UL>

Like MINERVA, PEGASUS does not propagate partial derivatives and thus 
cannot be used in any calculations during which derivative evaluation 
is in progress.

Initiating PEGASUS - The INITIATE statement for PEGASUS is:

<br><strong><br>INITIATE PEGASUS{</strong><em>(controller</em><strong>)}; 
{WITH FLAG</strong><em> signal</em><strong>;} </strong><BR><strong>{{AND|W</strong><em><strong>ITH} 
	LOWER{S} </strong>bottoms<strong>;} {{AND|WITH} UPPER{S} tops;}<BR></em>FOR<em> 
	model</em></strong><strong>; EQUATIONS ode/vars; OF ind-var; STEP delta; TO</strong><em> 
	limit </em><br><br>The meaning and use of the elements of this statement are exactly 
as described for MINERVA.  One additional operation performed by PEGASUS 
after the INTEGRATE statement has been executed is to adjust the value 
of DELTA to reflect its improved estimate of the integration step.  This 
permits subsequent integration, if any, to proceed using what is known 
to be an effective step-size.
	<P><strong><em>Controlling PEGASUS</em></strong> - The control variables for PEGASUS are:

	<table style="width: 100%" class="style6">
		<tr>
			<td><strong>Variable</strong></td>
			<td><strong>Description&nbsp;</strong></td>
			<td><strong>Preset Value&nbsp;</strong></td>
		</tr>
		<tr>
			<td><strong>EPSILON&nbsp;</strong></td>
			<td>EPSILON limiting convergence criterion.&nbsp;<br>If the equations are 
			integrated to a point at 
			<R>which any further steps would be less in 
			<R>absolute magnitude than EPSILON, then the 
			<R>limit has been reached and integration halts.<R>
		If EPSILON is zero, then it is automatically<R>
			set to the input step size times 0.001. </td>
			<td>0.001<D>
			&nbsp;</td>
		</tr>
		<tr>
			<td><strong>BOUND&nbsp;</strong></td>
			<td>Type of limiting option.&nbsp;<br>Zero selects normal limiting and 
			nonzero 
			<R>selects absolute limiting.

	</td>
			<td>0&nbsp;</td>
		</tr>
		<tr>
			<td style="height: 27px"><strong>ERRORMAX&nbsp;</strong></td>
			<td style="height: 27px">ERRMAX Maximum allowed local truncation 
			error.<br>If any equation incurs a relative error ABS(YERROR/Y)    
			<R>greater than MAXERR, then the step-size is reduced       
			<R>and the step is repeated.  The error is monitored              
			<R>continuously and the step is increased whenever the      
			<R>estimated error indicates that this would be profitable.       

	</td>
			<td style="height: 27px">0.0001&nbsp;</td>
		</tr>
		<tr>
			<td style="height: 26px"><strong>STEPMAX</strong></td>
			<td style="height: 26px">Maximum allowed step-size. <br>The preset 
			value effectively sets no limit. If the 
			<R>equations are potentially unstable, some appropriate 
			<R>upper bound on the step is advisable.

	</td>
			<td style="height: 26px">10<sup>9</sup></td>
		</tr>
		<tr>
			<td><strong>STEPMIN&nbsp;</strong></td>
			<td>Minimum allowed step-size. &nbsp;<br>This control is provided as a 
			protection against 
			<R>modeling errors or a choice of MAXERR which 
			<R>is incompatible with the differential equations. 
			<R>If error control requires a step smaller than this value,<R>
		integration terminates with a suitable diagnostic. 
			<R>Do not use this control as a method of disabling 
			<R>step-size mangement.  Instead choose a fixed-step 
			<R>solver such as MINERVA.

	</td>
			<td>10-9&nbsp;</td>
		</tr>
	</table>
	<h2>Guidelines for Selecting Solvers</h2>

From one viewpoint, differential equation solvers fall into two fundamental 
classes:
	<UL>
		<LI>Single-step solvers in which each integration step 
is entirely  independent of its predecessor, and</LI>
		<LI>Memory solvers in which information accumulated from 
one or more  prior steps is used to advance the integration.</LI>
	</UL>
</UL>
<p>Obviously, a memory method cannot be applied at the beginning of an 
interval, and thus all memory solvers employ a single-step method 
as a startup procedure.  As a result, any solver can be forced to 
execute in a single-step fashion by segmenting the problem into a 
sequence of short integrations, i.e. with each INTEGRATE statement 
encompassing no more than three or four steps.  This approach, however, 
is extremely undesirable.  Not only will the solver lose its unique 
benefits, such as error and step-size control, but also it will be 
less effective than any of the true single-step solvers.

The classification of the present solvers is as follows:

	</p>
<ul>
	<li><strong>SINGLE-STEP</strong>
	<ul>
		<li>MINERVA 
	</li>
		<li>PEGASUS
	</li>
		<li>ATHENA&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<br>
	<br>
	</li>
	</ul>
	</li>
	<li><strong>MEMORY</strong>
	<ul>
		<li>MERCURY
	</li>
		<li>NEPTUNE</li>
		<li>JANUS
	</li>
		<li>MERLIN
    </li>
		<li>ISIS
	</li>
		<li>JANISIS</li>
		<li>GEMINI </li><br>
	</ul>
	</li>
</ul>
<p>As might be expected, the memory solvers are generally superior to 
the others.  they are typically more efficient and offer more precise 
error control.  The single-step solvers, however, have some distinctive 
characteristics which make them the more desirable choice for certain 
problems.  These features and their consequences are summarized below.<BI><strong> 
&nbsp;</strong></p>
<P><strong>Comparing Execution Characteristics</strong> - In the single-step 
solvers, initialization of the integration process occurs at the INTEGRATE 
rather than the INITIATE statement.  The latter serves only to identify 
the variables and model to be used.  Hence, unlike the memory solvers, 
the INITIATE  statement does not invoke a model evaluation.  

	</p>
<P>One result is that the initial conditions and the value of the step-size 
need not be defined before the INITIATE statement.  Moreover, after 
the INTEGRATE statement has been executed, any of the key variables 
may be changed and integration may proceed without the need to re-initiate 
the solver.  This includes the dependent and independent variables, 
the step-size, the end point of integration, and the values of the 
limits.  Note, however, that changing any of these variables within 
the integration model itself is not permitted and will lead to indeterminate 
results.</p>
<P>In the case of a memory solver, the only variables which may be changed 
without re-initiation are the step-size and end point.  It should 
be understood that changing the  equations of integration, for example 
by altering a parameter used in the model, is tantamount to changing 
the dependent variable.  This is allowed (without  re-initiation) 
only for a single-step method.  There are two results of this greater 
freedom.  First, programming is simplified, particularly for problems 
involving discontinuities.  Secondly, less frequent re-initiation 
can lead to considerable time savings.  A common example is when nested 
within an optimization process.  Using a single-step  solver allows 
the INITIATE statement to be executed once only before beginning the 
problem solution.  With a memory solver, this must occur within the 
optimization model  because each iteration involves resetting the 
initial conditions. Also, in this case a TERMINATE statement is required 
to release internally used arrays. </strong>

	</p>
<P><strong>Guidelines for selecting the "best" integration solver</strong> - The 
choice of an appropriate integration solver depends upon several factors 
relating to the differential equations and the specific problem being 
solved.  The following table summarizes the selection guidelines in 
terms of the most significant factors.

	</p>
<table style="width: 100%" class="style6">
	<tr>
		<td>&nbsp;</td>
		<td>[1]&nbsp;</td>
		<td style="width: 44px">[2]&nbsp;</td>
		<td>[3]&nbsp;</td>
		<td>[4]&nbsp;</td>
		<td>[5]&nbsp;</td>
		<td>[6]&nbsp;</td>
		<td style="width: 45px">[7]&nbsp;</td>
		<td>[8]&nbsp;</td>
	</tr>
	<tr>
		<td>[A] Numerous Differential Equations</td>
		<td>N&nbsp;</td>
		<td style="width: 44px">S&nbsp;</td>
		<td>S&nbsp;</td>
		<td>A&nbsp;</td>
		<td>A&nbsp;</td>
		<td>A&nbsp;</td>
		<td style="width: 45px">A&nbsp;</td>
		<td>N&nbsp;</td>
	</tr>
	<tr>
		<td> 
	<MI>[B] High Precision Required</td>
		<td>A&nbsp;</td>
		<td style="width: 44px">S&nbsp;</td>
		<td>A&nbsp;</td>
		<td>N&nbsp;</td>
		<td>A&nbsp;</td>
		<td>S&nbsp;</td>
		<td style="width: 45px">A&nbsp;</td>
		<td>N&nbsp;</td>
	</tr>
	<tr>
		<td>[C] Problems of Instability 	
	</td>
		<td>N&nbsp;</td>
		<td style="width: 44px">N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>A&nbsp;</td>
		<td>S&nbsp;</td>
		<td style="width: 45px">A&nbsp;</td>
		<td>N&nbsp;</td>
	</tr>
	<tr>
		<td> 
	<MI>[D] Derivative Evaluation Required 
	</td>
		<td>N&nbsp;</td>
		<td style="width: 44px">N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>S&nbsp;</td>
		<td style="width: 45px">S&nbsp;</td>
		<td>A&nbsp;</td>
	</tr>
	<tr>
		<td>[E] Error Control Required</td>
		<td>S&nbsp;</td>
		<td style="width: 44px">S&nbsp;</td>
		<td>S&nbsp;</td>
		<td>A&nbsp;</td>
		<td>N&nbsp;</td>
		<td>S&nbsp;</td>
		<td style="width: 45px">N&nbsp;</td>
		<td>N&nbsp;</td>
	</tr>
	<tr>
		<td>[F] Single-Step Integration Only<D> </td>
		<td>N&nbsp;</td>
		<td style="width: 44px">N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>A&nbsp;</td>
		<td>S&nbsp;</td>
		<td>N&nbsp;</td>
		<td style="width: 45px">A&nbsp;</td>
		<td>A&nbsp;</td>
	</tr>
	<tr>
		<td> 
	<MI>[G] Limiting Required		
	</td>
		<td>N&nbsp;</td>
		<td style="width: 44px">N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>S&nbsp;</td>
		<td>S&nbsp;</td>
		<td>N&nbsp;</td>
		<td style="width: 45px">A&nbsp;</td>
		<td>N&nbsp;</td>
	</tr>
	<tr>
		<td>[H] Stiff Differential Equations<D> </td>
		<td>S&nbsp;</td>
		<td style="width: 44px">N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>N&nbsp;</td>
		<td>N&nbsp;</td>
		<td style="width: 45px">&nbsp;N</td>
		<td>N&nbsp;</td>
	</tr>
</table>
<p>Each column of the table identifies a solver according to the following 
list:  

	</p>
<p>[1] MERCURY </p>
<p>[2] NEPTUNE </p>
<p>[3] JANUS </p>
<p>[4] PEGASUS </p>
<p>[5] MINERVA </p>
<p>[6] MERLIN </p>
<p>[7]  ATHENA </p>
<P>[8]  ISIS </P>

<P>The two hybrid solvers, JANISIS and GEMINI, are not treated separately.  JANISIS 
has the characteristics of ISIS whenever derivative evaluation is 
in progress and those of JANUS otherwise. Similarly, GEMINI is like 
either MERLIN or NEPTUNE, according to the same distinction.  The 
table entries are coded as follows :

	</p>
<P>A - ACCEPTABLE  

	</p>
<P>S - SUPERIOR
<P>N - NOT APPLICABLE

	</p>
<P>In using this table, several solvers may appear to qualify for an 
application and, in fact, none of the listed criteria may be pertinent.  In 
either of these cases, the solver appearing highest in the list should 
be chosen, i.e. it is ordered roughly in terms of efficiency (MERCURY 
most efficient, etc.).
	</p>
<P>An amplification of the selection criteria is as follows:
	</p>
<P>&nbsp;[A] Numerous Differential Equations - The number 
of differential equations mainly affects the  computer memory requirements 
of the various solvers. those classified as "NOT APPLICABLE" are more 
properly specified as "space inefficient".  The definition of "numerous" 
is rather vague.  Perhaps any number greater than 100 or so (remembering 
to count each nth order equation as n equations).

	</p>
<P>[B] High Precision Required -  High precision may 
always be attained by a sufficiently small step-size, in conjunction 
(perhaps) with a high approximation order.  Unfortunately, very small 
steps can lead to large roundoff errors and unacceptable running times. 
NEPTUNE, MERLIN, and MERCURY provide methods which select the order 
and step-size so as to minimize the amount of computation needed to 
achieve a specified precision.  This is done on a step-by-step basis.  With 
no guarantee against a large global error buildup.  In practice, both 
NEPTUNE  and MERLIN have shown very favorable results, particularly 
when accuracies greater than 10<M^>-8<D> are desired.  

	</p>
<P>[C] Problems of Instability -  Detailed analysis 
of stability is a complex problem, but in<N>general all of the solvers 
are stable for sufficiently  small step-sizes.  MINERVA and ATHENA 
offer an option  (Runge-Kutta-Lawson) which allows steps from 2 to 
8 times as large as the other solvers before the instability region 
is approached for a given set of equations.  It should be  noted that 
this is not a matter of concern for many problems and that FC does 
provide unique tools (via the eigenvalues of the Jacobian) to determine 
a stable  step-size.  An excellent discussion of this and other  numerical 
points may be found in Lapidus and Seinfeld, 
	<MI>
<N>Numerical Solution 
Of Ordinary Differential Equations<D>  (1971).

	</p>
<P>[D] Derivative Evaluation Required -  Derivative 
evaluation is normally required by the optimization solvers, and thus 
this criterion is pertinent whenever the solution of differential 
equations is nested within an optimization process.  Examples are 
boundary value, parameter estimation, and optimal control problems. 


	</p>
<P>[E] Error Control Required -  Error control refers 
to management of the step-size and/or order of the technique to hold 
local truncation error within prescribed limits.  If not employed, 
conservative step-sizes must be used.  ISIS controls another source 
of error, roundoff, but this is usually not important except for very 
small steps or ill-conditioned systems of  equations.)

@NOBULLET = [F]  Single Step Integration Only - Normally, integration 
of one step per INTEGRATE statement is not required.  Actually, all 
of the solvers will allow this, but both MERCURY and JANUS revert 
to classical 4th order Runge-Kutta techniques in this instance and 
thereby lose all of their special advantages.  For MERCURY in particular, 
this will result in very inefficient integration.  The most common 
motivation for single steps is to allow tests for discontinuities 
or for special  operations such as printing intermediate values.  Usually 
these needs are better met by using the limiting features  (refer 
below).

	</p>
<P>[G] Limiting Required - Limiting is the process 
of imposing constant bounds on the  values of the dependent variables 
of integration.  The requirements for and the uses of limiting are 
described in detail in Section 5.7.

	</p>
<P>[H]  Stiff Differential Equations - Stiff systems, 
i.e. those characterized by both high and low frequency components, 
are often detected by obtaining widely varying results from integrations 
at different step-sizes.  When this problem is suspected, MERCURY 
is highly recommended as the choice.

</i></b> 

	</p>
